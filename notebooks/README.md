# 「Qiskitを使った量子最適化アルゴリズムの応用へ」のノートブック
本プロジェクトのノートブックファイルを管理する.

## 「Qiskitを使った量子最適化アルゴリズムの応用へ」ロードマップ
量子コンピュータの基礎から学び, 最適化の分野で量子コンピュータのユースケースを見つけることを目標にしたプロジェクト.  
本プロジェクトのロードマップを下記に記す.

### パート1 量子計算の基礎
量子コンピュータのアルゴリズムの基礎となる量子計算について理解する.  
対象のノートブックは `QuantumComputing01.ipynb`.

- 量子コンピュータとは
- 量子計算
- Qiskitの使い方

### パート2 量子もつれとアルゴリズム
有名な量子もつれを作成するアルゴリズムを理解する.  
対象のノートブックは `QuantumComputing02.ipynb`.

- GHZ状態
- W状態

### パート3 変分量子アルゴリズム
パラメータ付きの量子ゲートを使った変分量子アルゴリズムを理解する.

- VQE
- QAOA
- QML

### パート4 巡回セールスマン問題への適用
巡回セールスマン問題を量子アルゴリズムで解くためのワークフローを理解する.

- 組合せ最適化と2次計画問題
- イジングモデル
- 量子最適化アルゴリズムと状態数
- W状態を使った工夫

### パート5 配送計画問題への適用
TBD.

#### 原案
- QAOAでVRPを解く

### パート6 深層強化学習
TBD.

#### 原案
- 強化学習とは
- ニューラルネットワークを使った深層強化学習

### パート7 時系列解析を考慮した強化学習フレームワーク
TBD.

#### 原案
- 強化学習の時系列性
- RNNを使った深層強化学習
- LSTMを使った深層強化学習
- リザバーコンピューティング(ESN)を使った深層強化学習

### パート8 量子深層強化学習
TBD.

#### 原案
- TSPやVRPの問題, またはそれに近しい時系列解析的な観点から考えられる問題を普通の深層強化学習のフレームワークで解く
- RNN〜ESNを使った深層強化学習で問題を解く
- 量子アルゴリズムを組み込んだRNN系ニューラルネットワークを使った深層強化学習で問題を解く

### モチベーション
私の修士論文にて, 5都市のTSPをQAOAで解くために, 初期状態を生成する過程(全ての量子ビットにアダマールゲートをかける)で, W状態を用いたエンタングルメントを作ることにより状態数の爆発を抑えることが出来るようになり, シミュレーションで最適解を導くことが出来た.  
これは, 本プロジェクトのパート4までの内容に相当する.  
本プロジェクトでは, その先の組合せ最適化の分野での量子コンピュータのユースケースを探るべく, 挑戦的な内容を組み込んでいる.

### 注意点とFAQ
#### 注意点
まず, 全体的にQAOAにこだわるつもりはない.  
「変分量子アルゴリズムのユースケースを探す」というモチベーションが強く, 特に後半はQNNのフレームワークが活躍すると思っている.

#### FAQ
Q1. 量子計算の基礎とQiskitについて, Qiskitの基本操作に加えて, 「qiskit.optimization」を使った組合せ最適化の具体例も早めに触れておくと, QAOAへの理解がスムーズになるかも?  
$\rightarrow$ QAOAは, 第3章で具体例を混ぜながら解説するので, ここでは不要だと考える. 特に, QAOAは量子アルゴリズムの1種でしかなく, VQE「でも」良いし, QAOAにこだわる必要は無い.

Q2. GHZ状態とW状態の作成に関して, どのように組合せ最適化問題に応用するのかが鍵になりそう. 特にW状態を用いて状態空間の爆発を抑える, という発想は面白いが, 具体的にどう適用するかの検討が必要そう.  
$\rightarrow$ QAOAの初期状態の作成の際に, 全部の量子ビットにアダマールゲートをかけるが, そうするとTSPの場合の状態数は都市数 $n$ に対して$2^{n^2}$として表すことが出来る. これは全探索で求める実行可能解の数 $(n - 1)!$ と比べ, 一般的に非常に大きくなってしまう. ここにW状態を用いることで, 上手い具合にエンタングルさせることが出来て, 理論上 $(n - 1)^{n - 1}$ にまで減らすことが出来る.

Q3. QAOAに関しては, まず単純なグラフ問題(Max-Cut問題など)をQAOAで解く経験を積んだ後, TSPやVRPのようなより複雑な問題へ発展させるのが良さそう.  
$\rightarrow$ QAOAにあまりフォーカスはしていない. ここでは変分量子アルゴリズムがどういうものなのかをそれぞれ理論的な説明をする場になっている. もちろん簡単な使い方は示すが, あまり話をややこしくしすぎないようにするのがポイントである.

Q4. 巡回セールスマン問題(TSP)はハミルトニアン回帰問題として定式化可能だが, QAOAでどの程度の精度が出るかが課題である. 特に, 小規模な問題から検証しつつ, どこで古典アルゴリズムと比べるのかを明確にするべきでは?  
$\rightarrow$ TSPをQAOAで解くのは正直限界がある. それは承知の上であり, それでもQAOAという量子アルゴリズムで組合せ最適化問題を解こうとするアプローチが存在する(考えられてきている)ことは初学者にもアピールポイントとなるはず.

Q5. TSPの発展形であるVRPは制約が増えるため, QAOAだけでは厳しいかもしれない. 例えば, 制約をペナルティ項としてエネルギー関数に埋め込む手法を検討すると良さそう.  
$\rightarrow$ VRPに適用するのは未知数である. 私自身TSPではやったことがあるものの, VRPはそもそも問題として考えたことが無かったので, 出来るところまでやってみたいというモチベーションである.

Q6. VRPを強化学習で解くには, ルート決定をエージェントのアクションとするアプローチ(Pointer Network + RLなど)が考えられる. ここでRNNを使うのは妥当だが, LSTM vs ESN(リザバーコンピューティング)の使い分けについては, もう少し具体的な検討が必要では? また, 量子系のリザバーコンピューティング(Quantum Reservoir Computing, QRC)という研究領域もあるので, もしRNN系と組み合わせるなら, 量子リザバーを取り入れる方向も考えられる.  
$\rightarrow$ VRPやTSPのような最適化問題は, 深層強化学習のフレームワークで解かれているという前例があるらしい(私は詳しくない). そもそも, 私の理解では強化学習において時刻 $t$ における諸々の状態が重要であり, それを時系列データと捉えることができると考える. よって, 時系列解析用の深層学習モデルであるRNNやLSTM, リザバーコンピューティングは深層強化学習と相性が良いのではないかと考えた. 使い分けというのは意図が違い, ここでは「時系列解析深層学習モデル」と「強化学習」の結びつきを強調するために, また, 言う通り最後の章で量子リザバーという形で使うことを目指して段階的にESNなどの導入を行いたいと思っていたところ.

Q7. 量子深層強化学習について, ここはまだ未開拓な分野だが, 量子ニューラルネット(QNN)と深層強化学習を組み合わせた研究が増えてきており, 例えば, QAOAのパラメータを強化学習で最適化するような手法や, 量子ボルツマンマシン(QBM)を活用する方法がある. 量子アルゴリズムが時系列強化学習とどのように絡むかについては, もう少しアイデアの具体化が必要そう.  
$\rightarrow$ 量子深層強化学習をどのように考えるかということであれば, 組合せ最適化問題に適用するための量子リザバーを組み込んだ強化学習法を試すことが本プロジェクトの最終目的である. もちろん, 上手くいくかは想像つかないので, 全くダメだったということでもそれは結果として意味があることだと考える.